{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ak6fEzhhK9Rz"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np  # linear algebra\n",
        "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss,accuracy_score, confusion_matrix, classification_report, roc_auc_score, mean_squared_error, f1_score"
      ],
      "metadata": {
        "id": "RMEG1PY-LFgY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=pd.read_csv(\"/kaggle/input/mle-ese-mock/train (5).csv\")\n",
        "test=pd.read_csv(\"/kaggle/input/mle-ese-mock/test (4).csv\")\n",
        "train.info()"
      ],
      "metadata": {
        "id": "zHXxkPrPLIsn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "j4TJNwuJLMmY",
        "outputId": "3fac3c7f-e170-487c-ffd1-a9053f95da33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (2250, 16)\n",
            "Test shape: (750, 15)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sample_submission' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1314987219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample submission shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sample_submission' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "4yZMLrz1LOmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "l7JtkmwFLS4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.isnull().sum()"
      ],
      "metadata": {
        "id": "QE4HqZfOLZQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ids = train['id']    # remove only if id column present in the train dataset\n",
        "train.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "hHxj4tJhLf2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=['quality_grade'])   # put your target column here\n",
        "y = train['quality_grade']"
      ],
      "metadata": {
        "id": "b8WUfwr9LlJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "zAJkaq6MLotB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X.select_dtypes(include=['object']).columns\n"
      ],
      "metadata": {
        "id": "or1Lcz5ILsHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nums_cols=x.select_dtypes(include=[\"int64\",\"float64\"]).columns\n",
        "X[numeric_features].hist(figsize=(14,10))\n",
        "plt.suptitle(\"Numerical Feature Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ILPoPBImLu1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,10))\n",
        "sns.heatmap(train[numeric_features].corr(),annot=False,cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation between numerical features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O9KiNScLL4Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "metadata": {
        "id": "2dJzfCpUL-Iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ],
      "metadata": {
        "id": "xPmqsxlOMBP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n"
      ],
      "metadata": {
        "id": "kDYBpdlbME3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "LUp4AmolTnlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "model = HistGradientBoostingClassifier(\n",
        "    loss=\"log_loss\",        # IMPORTANT\n",
        "    max_iter=100,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    min_samples_leaf=30,\n",
        "    l2_regularization=0.1,\n",
        "    max_bins=255,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "NXWOyNq-TpMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', model)\n",
        "])"
      ],
      "metadata": {
        "id": "HysQS_uiTsgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)"
      ],
      "metadata": {
        "id": "iiv9tyTwTunM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "y_pred_proba = pipeline.predict_proba(X_test)\n",
        "loss = log_loss(y_test, y_pred_proba)\n",
        "print(f\"\\n✅ Log Loss on validation set: {loss:.5f}\")"
      ],
      "metadata": {
        "id": "YNS6xtSxTwfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=pipeline.predict(X_test)\n",
        "accuracy=accuracy_score(y_pred,y_test)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "smWoOtXiUVvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_pred,y_test)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "EMbIctqoUXTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1=f1_score(y_test,y_pred,average='weighted')\n",
        "print(f1)"
      ],
      "metadata": {
        "id": "DfQWLDBMUZDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_square=mean_squared_error(y_test,y_pred,squared=False)\n",
        "print(mean_square)"
      ],
      "metadata": {
        "id": "mRepfhOrUaut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\")\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.xlabel(\"Predicted value\")\n",
        "plt.ylabel(\"Actual value\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eM_jQ0yRUcHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = test['id']\n",
        "test.drop(columns=['id'], inplace=True)"
      ],
      "metadata": {
        "id": "NdvXhQ01Udf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = pipeline.predict_proba(test)\n",
        "class_names = le.classes_  # use label encoder mapping\n",
        "submission = pd.DataFrame(probs, columns=[f\"Status_{cls}\" for cls in class_names])\n",
        "submission.insert(0, 'id', test_ids)"
      ],
      "metadata": {
        "id": "9_jochAuUfih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"submission3.csv\", index=False)\n",
        "print(\"\\n✅ Submission file created successfully!\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "id": "2L2DwpUbUhI8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}